{
    "1067": {
        "End2End_cpu": {
            "score_train": [
                -0.8755186796188354,
                -0.8867812752723694,
                -0.8660343885421753,
                -0.8808535933494568,
                -0.8732227683067322
            ],
            "score_test": [
                -0.8436018824577332,
                -0.8317535519599915,
                -0.8578199148178101,
                -0.879146933555603,
                -0.8646080493927002
            ],
            "t_fit": [
                9.151191055774689,
                19.762380562722683,
                2.029084265232086,
                6.9038562178611755,
                11.71667218953371
            ],
            "t_inference": [
                0.13868404924869537,
                0.5422457009553909,
                0.018923968076705933,
                0.0846981480717659,
                0.18218842148780823
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 301,
                    "lr": 0.027655127744458906,
                    "end_lr_factor": 0.10843055471990928,
                    "n_epochs": 28,
                    "weight_decay": 0.00023196615385205431,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 386,
                    "lr": 0.00296584146833975,
                    "end_lr_factor": 0.08127263032761635,
                    "n_epochs": 12,
                    "weight_decay": 5.798200978313302e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 99,
                    "lr": 0.08365064583034183,
                    "end_lr_factor": 0.016672297702288317,
                    "n_epochs": 29,
                    "weight_decay": 1.7734886150017156e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 305,
                    "lr": 0.007170458243297225,
                    "end_lr_factor": 0.6166113778323079,
                    "n_epochs": 31,
                    "weight_decay": 6.967020764020324e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 135,
                    "lr": 0.010709408003597907,
                    "end_lr_factor": 0.29970861703989027,
                    "n_epochs": 27,
                    "weight_decay": 4.1479751371403e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}
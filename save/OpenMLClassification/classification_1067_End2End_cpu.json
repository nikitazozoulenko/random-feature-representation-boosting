{
    "1067": {
        "End2End_cpu": {
            "score_train": [
                -0.8772969841957092,
                -0.9010077118873596,
                -0.9425014853477478,
                -0.8873740434646606,
                -0.8726303577423096
            ],
            "score_test": [
                -0.8530805706977844,
                -0.8412322402000427,
                -0.8601895570755005,
                -0.8649289011955261,
                -0.8598574995994568
            ],
            "t_fit": [
                17.06769759207964,
                6.505531571805477,
                25.51077627390623,
                37.71615993231535,
                1.195543922483921
            ],
            "t_inference": [
                0.21239988505840302,
                0.19456426799297333,
                0.37659740447998047,
                0.7278029099106789,
                0.03705762326717377
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 265,
                    "lr": 0.007043248424301535,
                    "end_lr_factor": 0.5047110758724865,
                    "n_epochs": 17,
                    "weight_decay": 2.7394057878591717e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 154,
                    "lr": 0.00595391054838297,
                    "end_lr_factor": 0.4260093150255107,
                    "n_epochs": 14,
                    "weight_decay": 1.0216424951940148e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 354,
                    "lr": 0.0010383928463198648,
                    "end_lr_factor": 0.17789332626429935,
                    "n_epochs": 23,
                    "weight_decay": 2.1097129031065515e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 509,
                    "lr": 0.0018205683423902566,
                    "end_lr_factor": 0.5263102619131163,
                    "n_epochs": 14,
                    "weight_decay": 1.0422560591323317e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 86,
                    "lr": 0.005927006654963606,
                    "end_lr_factor": 0.19983276575501646,
                    "n_epochs": 12,
                    "weight_decay": 3.573903711444545e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}
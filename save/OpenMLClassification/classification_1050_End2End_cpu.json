{
    "1050": {
        "End2End_cpu": {
            "score_train": [
                -0.9160000085830688,
                -0.9215999841690063,
                -0.9327999949455261,
                -0.902478039264679,
                -0.9168664813041687
            ],
            "score_test": [
                -0.9009584784507751,
                -0.8881788849830627,
                -0.8817891478538513,
                -0.8942307829856873,
                -0.8942307829856873
            ],
            "t_fit": [
                5.19541454128921,
                6.644797740504146,
                8.995741162449121,
                2.6030814684927464,
                26.2264363206923
            ],
            "t_inference": [
                0.16899648308753967,
                0.10857793316245079,
                0.24373388662934303,
                0.0804155208170414,
                0.2658825684338808
            ],
            "hyperparams": [
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 372,
                    "lr": 0.03158683129062826,
                    "end_lr_factor": 0.18418776817629198,
                    "n_epochs": 10,
                    "weight_decay": 0.00017005074683253582,
                    "batch_size": 128
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 165,
                    "lr": 0.03703010692838861,
                    "end_lr_factor": 0.7165390542717347,
                    "n_epochs": 27,
                    "weight_decay": 0.0001996006932582816,
                    "batch_size": 384
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 387,
                    "lr": 0.004200748103305691,
                    "end_lr_factor": 0.1737517998021751,
                    "n_epochs": 13,
                    "weight_decay": 2.811232469917752e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 386,
                    "lr": 0.004448048706478103,
                    "end_lr_factor": 0.653634923548896,
                    "n_epochs": 16,
                    "weight_decay": 2.8200100716335643e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 389,
                    "lr": 0.041933191859865215,
                    "end_lr_factor": 0.28631119253343507,
                    "n_epochs": 44,
                    "weight_decay": 0.0002087444410305454,
                    "batch_size": 384
                }
            ]
        }
    }
}
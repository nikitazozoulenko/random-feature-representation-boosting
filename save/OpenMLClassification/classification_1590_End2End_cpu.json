{
    "1590": {
        "End2End_cpu": {
            "score_train": [
                -0.9027500152587891,
                -0.9110000133514404,
                -0.8987500071525574,
                -0.9022499918937683,
                -0.8912500143051147
            ],
            "score_test": [
                -0.8489999771118164,
                -0.8429999947547913,
                -0.8429999947547913,
                -0.8500000238418579,
                -0.8479999899864197
            ],
            "t_fit": [
                24.77874582260847,
                14.863421514630318,
                24.116345956921577,
                16.458582289516926,
                5.661390922963619
            ],
            "t_inference": [
                1.1031687706708908,
                0.502246543765068,
                1.0685850232839584,
                0.6046956032514572,
                0.16084998100996017
            ],
            "hyperparams": [
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 347,
                    "lr": 0.003749970256728146,
                    "end_lr_factor": 0.48577251920494785,
                    "n_epochs": 11,
                    "weight_decay": 1.719076820176002e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 224,
                    "lr": 0.007041830285015997,
                    "end_lr_factor": 0.7321173243252596,
                    "n_epochs": 10,
                    "weight_decay": 1.306699123790696e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 337,
                    "lr": 0.004141578993867181,
                    "end_lr_factor": 0.3382489369034439,
                    "n_epochs": 11,
                    "weight_decay": 2.1290703171202993e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 206,
                    "lr": 0.009463858974439247,
                    "end_lr_factor": 0.9954092520256412,
                    "n_epochs": 10,
                    "weight_decay": 1.0261131941550911e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 105,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 475,
                    "lr": 0.007162344076415071,
                    "end_lr_factor": 0.02676886168188963,
                    "n_epochs": 13,
                    "weight_decay": 1.641278727029849e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}
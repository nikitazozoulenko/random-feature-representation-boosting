{
    "38": {
        "End2End_cpu": {
            "score_train": [
                -0.998342752456665,
                -0.9986741542816162,
                -0.9973492622375488,
                -0.9973492622375488,
                -0.9953611493110657
            ],
            "score_test": [
                -0.9788079261779785,
                -0.9761589169502258,
                -0.970822274684906,
                -0.9814323782920837,
                -0.9787798523902893
            ],
            "t_fit": [
                40.33480542898178,
                23.393038854002953,
                29.17362329363823,
                61.780688755214214,
                20.500034615397453
            ],
            "t_inference": [
                0.26596295088529587,
                0.19809497892856598,
                0.25832780450582504,
                0.5591640695929527,
                0.10001704096794128
            ],
            "hyperparams": [
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 102,
                    "lr": 0.012580836314903171,
                    "end_lr_factor": 0.015562497317416768,
                    "n_epochs": 44,
                    "weight_decay": 9.155310801709255e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 408,
                    "lr": 0.009266039414770113,
                    "end_lr_factor": 0.036277114211414274,
                    "n_epochs": 35,
                    "weight_decay": 0.0002264917192942783,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 88,
                    "lr": 0.017372794904073636,
                    "end_lr_factor": 0.07040137652410783,
                    "n_epochs": 46,
                    "weight_decay": 0.00023160533733696957,
                    "batch_size": 256
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 284,
                    "lr": 0.011922406088752885,
                    "end_lr_factor": 0.011463464096652347,
                    "n_epochs": 39,
                    "weight_decay": 0.0005263556695188514,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 170,
                    "lr": 0.0992287753446725,
                    "end_lr_factor": 0.1128500962897323,
                    "n_epochs": 42,
                    "weight_decay": 1.5275012553134454e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}
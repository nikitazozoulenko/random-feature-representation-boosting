{
    "38": {
        "End2End_cpu": {
            "score_train": [
                -0.9946967363357544,
                -0.9993370771408081,
                -0.9990059733390808,
                -0.9990059733390808,
                -0.9917163848876953
            ],
            "score_test": [
                -0.9748344421386719,
                -0.9761589169502258,
                -0.9787798523902893,
                -0.9787798523902893,
                -0.982758641242981
            ],
            "t_fit": [
                25.215722039341927,
                106.18357929214835,
                33.11114464327693,
                36.670449174940586,
                16.14987564459443
            ],
            "t_inference": [
                0.42497795075178146,
                0.8186323419213295,
                0.26785511150956154,
                0.2757287360727787,
                0.09813069924712181
            ],
            "hyperparams": [
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 387,
                    "lr": 0.0006917769429279539,
                    "end_lr_factor": 0.7102590006894521,
                    "n_epochs": 15,
                    "weight_decay": 4.0273769431284785e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 418,
                    "lr": 0.0020261359328361166,
                    "end_lr_factor": 0.10737093693981896,
                    "n_epochs": 44,
                    "weight_decay": 0.00031058764877143883,
                    "batch_size": 256
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 455,
                    "lr": 0.000492368353808683,
                    "end_lr_factor": 0.4399190733810155,
                    "n_epochs": 40,
                    "weight_decay": 6.50147048216255e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 387,
                    "lr": 0.0008222939036793858,
                    "end_lr_factor": 0.18693776823109493,
                    "n_epochs": 38,
                    "weight_decay": 2.7076182689951387e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 53,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 46,
                    "lr": 0.0061424992506091585,
                    "end_lr_factor": 0.2099525290498503,
                    "n_epochs": 41,
                    "weight_decay": 0.0004032474739160098,
                    "batch_size": 128
                }
            ]
        }
    }
}
{
    "1068": {
        "End2End_cpu": {
            "score_train": [
                -0.9368658661842346,
                -0.9605411291122437,
                -0.9875986576080322,
                -0.9368658661842346,
                -0.9448198080062866
            ],
            "score_test": [
                -0.9369369149208069,
                -0.9144144058227539,
                -0.9189189076423645,
                -0.9414414167404175,
                -0.9230769276618958
            ],
            "t_fit": [
                14.151767164468765,
                32.31926466524601,
                10.006472408771515,
                2.848092421889305,
                1.9302947372198105
            ],
            "t_inference": [
                0.16098496317863464,
                0.20889802277088165,
                0.05564314126968384,
                0.08372126519680023,
                0.06219568848609924
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 194,
                    "lr": 0.004389227225562281,
                    "end_lr_factor": 0.3672502542010268,
                    "n_epochs": 10,
                    "weight_decay": 1.703517143855937e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 423,
                    "lr": 0.003980908531260202,
                    "end_lr_factor": 0.06334779301695641,
                    "n_epochs": 45,
                    "weight_decay": 0.0004084003543799203,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 508,
                    "lr": 0.001193479781387418,
                    "end_lr_factor": 0.34677203103126125,
                    "n_epochs": 50,
                    "weight_decay": 5.5745385941310454e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 340,
                    "lr": 0.007154211506434623,
                    "end_lr_factor": 0.18932896887721465,
                    "n_epochs": 12,
                    "weight_decay": 2.6340835050522913e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 110,
                    "lr": 0.00952212896305241,
                    "end_lr_factor": 0.6966147037880454,
                    "n_epochs": 12,
                    "weight_decay": 2.9896048647091555e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
{
    "1068": {
        "End2End_cpu": {
            "score_train": [
                -0.9346110224723816,
                -0.9334836602210999,
                -0.9368658661842346,
                -0.9357384443283081,
                -0.9459459185600281
            ],
            "score_test": [
                -0.9369369149208069,
                -0.9099099040031433,
                -0.9324324131011963,
                -0.9369369149208069,
                -0.9230769276618958
            ],
            "t_fit": [
                4.8869800716638565,
                3.2190801352262497,
                5.8147033378481865,
                1.112655185163021,
                2.2120788022875786
            ],
            "t_inference": [
                0.06413616240024567,
                0.09656992554664612,
                0.1297386735677719,
                0.016617923974990845,
                0.04976232349872589
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 415,
                    "lr": 0.013445571581487717,
                    "end_lr_factor": 0.2556702855362546,
                    "n_epochs": 47,
                    "weight_decay": 2.7812253071801806e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 247,
                    "lr": 0.013925030779457725,
                    "end_lr_factor": 0.5960710360410058,
                    "n_epochs": 11,
                    "weight_decay": 5.072283738295758e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 298,
                    "lr": 0.010012406180641963,
                    "end_lr_factor": 0.0881778540277946,
                    "n_epochs": 19,
                    "weight_decay": 3.6961976621486205e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 167,
                    "lr": 0.0724523105491087,
                    "end_lr_factor": 0.6545145378004238,
                    "n_epochs": 15,
                    "weight_decay": 1.4776589453538e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 292,
                    "lr": 0.024977085852188302,
                    "end_lr_factor": 0.17503565844014324,
                    "n_epochs": 17,
                    "weight_decay": 2.3583702751322727e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
{
    "37": {
        "End2End_cpu": {
            "score_train": [
                -0.791530966758728,
                -0.8159608840942383,
                -0.8045602440834045,
                -0.8195121884346008,
                -0.8048780560493469
            ],
            "score_test": [
                -0.7792207598686218,
                -0.7922077775001526,
                -0.7532467246055603,
                -0.7124183177947998,
                -0.7777777910232544
            ],
            "t_fit": [
                0.23850271478295326,
                0.7552755251526833,
                1.379354476928711,
                1.3147619664669037,
                1.213657408952713
            ],
            "t_inference": [
                0.012230511754751205,
                0.016955513507127762,
                0.04534705728292465,
                0.04481211677193642,
                0.03155926614999771
            ],
            "hyperparams": [
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 91,
                    "lr": 0.006423836962969459,
                    "end_lr_factor": 0.5647029694848689,
                    "n_epochs": 10,
                    "weight_decay": 2.5407255928477137e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 220,
                    "lr": 0.006349815044652408,
                    "end_lr_factor": 0.2686740517377074,
                    "n_epochs": 13,
                    "weight_decay": 1.80065535774717e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 139,
                    "lr": 0.005596199857569791,
                    "end_lr_factor": 0.5951358456302319,
                    "n_epochs": 17,
                    "weight_decay": 5.629987103435091e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 224,
                    "lr": 0.007041830285015997,
                    "end_lr_factor": 0.7321173243252596,
                    "n_epochs": 10,
                    "weight_decay": 1.306699123790696e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 295,
                    "lr": 0.003903403318304432,
                    "end_lr_factor": 0.5841593326380006,
                    "n_epochs": 16,
                    "weight_decay": 1.0026999671365334e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
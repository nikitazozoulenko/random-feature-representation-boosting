{
    "37": {
        "End2End_cpu": {
            "score_train": [
                -0.8094462752342224,
                -0.8420195579528809,
                -0.7996742725372314,
                -0.8211382031440735,
                -0.8487805128097534
            ],
            "score_test": [
                -0.7922077775001526,
                -0.7922077775001526,
                -0.7532467246055603,
                -0.7254902124404907,
                -0.7712418437004089
            ],
            "t_fit": [
                0.640856065787375,
                1.2767239809036255,
                0.9382707527838647,
                0.4709658925421536,
                1.651823213789612
            ],
            "t_inference": [
                0.012106889393180609,
                0.019679980352520943,
                0.028120407834649086,
                0.01086508110165596,
                0.029375405050814152
            ],
            "hyperparams": [
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 34,
                    "lr": 0.017869922921142523,
                    "end_lr_factor": 0.15763559115022854,
                    "n_epochs": 17,
                    "weight_decay": 1.598613202368104e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 156,
                    "lr": 0.022845655322373908,
                    "end_lr_factor": 0.5239619507609593,
                    "n_epochs": 25,
                    "weight_decay": 1.7938875625981285e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 241,
                    "lr": 0.0045311230420998555,
                    "end_lr_factor": 0.09586830817557215,
                    "n_epochs": 11,
                    "weight_decay": 1.7637117080289214e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 291,
                    "lr": 0.0486951032123438,
                    "end_lr_factor": 0.09173182998539467,
                    "n_epochs": 11,
                    "weight_decay": 2.187839511835058e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 8,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 44,
                    "lr": 0.01653966679816487,
                    "end_lr_factor": 0.025994909793022224,
                    "n_epochs": 26,
                    "weight_decay": 6.098783585663809e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
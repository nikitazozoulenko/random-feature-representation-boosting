{
    "23517": {
        "End2End_cpu": {
            "score_train": [
                -0.5575000047683716,
                -0.643750011920929,
                -0.6320000290870667,
                -0.6712499856948853,
                -0.6165000200271606
            ],
            "score_test": [
                -0.47999998927116394,
                -0.4819999933242798,
                -0.4790000021457672,
                -0.4909999966621399,
                -0.5130000114440918
            ],
            "t_fit": [
                8.162324972450733,
                22.817575551569462,
                12.958192519843578,
                14.641335919499397,
                10.696024984121323
            ],
            "t_inference": [
                0.13633226603269577,
                0.25576353818178177,
                0.3539685383439064,
                0.4894228130578995,
                0.03372717648744583
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 16,
                    "lr": 9.260722937249008e-06,
                    "end_lr_factor": 0.5588691038669175,
                    "n_epochs": 25,
                    "weight_decay": 1.56228558704958e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 80,
                    "lr": 5.886677160746845e-06,
                    "end_lr_factor": 0.3498227300675483,
                    "n_epochs": 29,
                    "weight_decay": 9.590216683992864e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 242,
                    "lr": 0.021168311192400906,
                    "end_lr_factor": 0.46757556107650183,
                    "n_epochs": 14,
                    "weight_decay": 1.4547307271298078e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 226,
                    "lr": 0.010841229528235354,
                    "end_lr_factor": 0.2821470815933942,
                    "n_epochs": 12,
                    "weight_decay": 6.271829652093058e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 24,
                    "lr": 2.9104483531810055e-05,
                    "end_lr_factor": 0.030673756918996556,
                    "n_epochs": 41,
                    "weight_decay": 8.96707641297066e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}
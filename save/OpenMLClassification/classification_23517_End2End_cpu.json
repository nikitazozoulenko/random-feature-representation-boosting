{
    "23517": {
        "End2End_cpu": {
            "score_train": [
                -0.5220000147819519,
                -0.5202500224113464,
                -0.6692500114440918,
                -0.5230000019073486,
                -0.5214999914169312
            ],
            "score_test": [
                -0.4970000088214874,
                -0.5070000290870667,
                -0.49300000071525574,
                -0.5009999871253967,
                -0.5
            ],
            "t_fit": [
                40.520654456689954,
                31.443026715889573,
                15.284113451838493,
                8.793045518919826,
                12.51595995388925
            ],
            "t_inference": [
                0.9215807672590017,
                0.38688875176012516,
                0.12344014830887318,
                0.14343101903796196,
                0.17444303631782532
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 216,
                    "lr": 2.520046166932674e-07,
                    "end_lr_factor": 0.32400418622641713,
                    "n_epochs": 23,
                    "weight_decay": 1.437412749876924e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 112,
                    "lr": 4.331230367995876e-07,
                    "end_lr_factor": 0.40751241916523917,
                    "n_epochs": 22,
                    "weight_decay": 6.185990434380031e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 42,
                    "lr": 2.5956326731481226e-05,
                    "end_lr_factor": 0.02170082416544176,
                    "n_epochs": 35,
                    "weight_decay": 1.2366356130978815e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 19,
                    "lr": 4.66665899840539e-06,
                    "end_lr_factor": 0.27575110870824854,
                    "n_epochs": 30,
                    "weight_decay": 6.423753378187117e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 59,
                    "lr": 1.1662695623162354e-06,
                    "end_lr_factor": 0.0801655817807222,
                    "n_epochs": 24,
                    "weight_decay": 3.921642468117781e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
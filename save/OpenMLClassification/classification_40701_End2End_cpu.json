{
    "40701": {
        "End2End_cpu": {
            "score_train": [
                -0.9750000238418579,
                -0.9727500081062317,
                -1.0,
                -0.9754999876022339,
                -0.9735000133514404
            ],
            "score_test": [
                -0.9589999914169312,
                -0.9580000042915344,
                -0.9350000023841858,
                -0.9449999928474426,
                -0.9570000171661377
            ],
            "t_fit": [
                21.939857073128223,
                4.989376492798328,
                75.40681286156178,
                28.436351418495178,
                52.25267745554447
            ],
            "t_inference": [
                0.12466124445199966,
                0.18509116768836975,
                0.7272238582372665,
                0.14641936123371124,
                0.26277243345975876
            ],
            "hyperparams": [
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 79,
                    "lr": 0.07172873173955867,
                    "end_lr_factor": 0.02048343146640483,
                    "n_epochs": 42,
                    "weight_decay": 0.0008077099370598817,
                    "batch_size": 128
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 60,
                    "lr": 0.043099350580762065,
                    "end_lr_factor": 0.05469794638167342,
                    "n_epochs": 10,
                    "weight_decay": 0.0008581981523392587,
                    "batch_size": 384
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 437,
                    "lr": 0.0013928899870365402,
                    "end_lr_factor": 0.01944748807666737,
                    "n_epochs": 44,
                    "weight_decay": 0.0003021465564867427,
                    "batch_size": 384
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 122,
                    "lr": 0.09791873599642521,
                    "end_lr_factor": 0.013823193095974731,
                    "n_epochs": 50,
                    "weight_decay": 0.000604936282709759,
                    "batch_size": 128
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 110,
                    "lr": 0.08614801646195999,
                    "end_lr_factor": 0.010013250557871986,
                    "n_epochs": 50,
                    "weight_decay": 0.0009770421432936042,
                    "batch_size": 128
                }
            ]
        }
    }
}
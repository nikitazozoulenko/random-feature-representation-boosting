{
    "40701": {
        "End2End_cpu": {
            "score_train": [
                -0.9729999899864197,
                -0.9679999947547913,
                -0.9994999766349792,
                -0.9825000166893005,
                -0.9757500290870667
            ],
            "score_test": [
                -0.9430000185966492,
                -0.9480000138282776,
                -0.9150000214576721,
                -0.9340000152587891,
                -0.9449999928474426
            ],
            "t_fit": [
                12.436405008658767,
                21.18712487258017,
                40.63756143860519,
                3.429125452414155,
                38.27896424382925
            ],
            "t_inference": [
                0.20049498230218887,
                0.8862810116261244,
                0.4455781318247318,
                0.11285793967545033,
                1.2953014634549618
            ],
            "hyperparams": [
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 38,
                    "lr": 0.009942955949856547,
                    "end_lr_factor": 0.12687847034217803,
                    "n_epochs": 14,
                    "weight_decay": 1.0566951647166316e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 398,
                    "lr": 0.004190473673671517,
                    "end_lr_factor": 0.051755270651474616,
                    "n_epochs": 11,
                    "weight_decay": 1.4506588656839225e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 507,
                    "lr": 0.0010088592100720253,
                    "end_lr_factor": 0.3849001810880893,
                    "n_epochs": 25,
                    "weight_decay": 1.1554168269590567e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 38,
                    "lr": 0.0034290680492209884,
                    "end_lr_factor": 0.10199782511699548,
                    "n_epochs": 10,
                    "weight_decay": 1.5235968061812755e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 33,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 460,
                    "lr": 0.004092986620790445,
                    "end_lr_factor": 0.07074610006520324,
                    "n_epochs": 12,
                    "weight_decay": 3.4940735708096125e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}
{
    "1464": {
        "End2End_cpu": {
            "score_train": [
                -0.782608687877655,
                -0.8093645572662354,
                -0.829431414604187,
                -0.8146911263465881,
                -0.8330550789833069
            ],
            "score_test": [
                -0.800000011920929,
                -0.8133333325386047,
                -0.7266666889190674,
                -0.7986577153205872,
                -0.744966447353363
            ],
            "t_fit": [
                17.901228161528707,
                13.583586232736707,
                9.650647904723883,
                0.9704466965049505,
                1.2924451399594545
            ],
            "t_inference": [
                0.1522367037832737,
                0.08093306422233582,
                0.07343556545674801,
                0.014893027022480965,
                0.007865948602557182
            ],
            "hyperparams": [
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 391,
                    "lr": 0.004385384202327436,
                    "end_lr_factor": 0.7193637401179717,
                    "n_epochs": 16,
                    "weight_decay": 1.6057385339536692e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 315,
                    "lr": 0.0009054598242969793,
                    "end_lr_factor": 0.17858907388772535,
                    "n_epochs": 44,
                    "weight_decay": 2.1018885773396377e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 357,
                    "lr": 0.003085626521479865,
                    "end_lr_factor": 0.15565520051192525,
                    "n_epochs": 47,
                    "weight_decay": 1.932916148479142e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 136,
                    "lr": 0.002505514181078325,
                    "end_lr_factor": 0.08351836463638004,
                    "n_epochs": 19,
                    "weight_decay": 2.7949514118170246e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 64,
                    "lr": 0.002224983015352794,
                    "end_lr_factor": 0.14086524702370315,
                    "n_epochs": 50,
                    "weight_decay": 2.2495610140223678e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}
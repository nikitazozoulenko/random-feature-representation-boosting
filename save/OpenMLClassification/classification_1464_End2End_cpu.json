{
    "1464": {
        "End2End_cpu": {
            "score_train": [
                -0.7943143844604492,
                -0.807692289352417,
                -0.851170539855957,
                -0.7429048418998718,
                -0.826377272605896
            ],
            "score_test": [
                -0.8333333134651184,
                -0.8066666722297668,
                -0.6933333277702332,
                -0.7583892345428467,
                -0.7516778707504272
            ],
            "t_fit": [
                0.9175207689404488,
                1.0170363634824753,
                4.638621479272842,
                2.066823683679104,
                3.629015192389488
            ],
            "t_inference": [
                0.011623330414295197,
                0.0062389373779296875,
                0.03384510427713394,
                0.044357433915138245,
                0.052463412284851074
            ],
            "hyperparams": [
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 61,
                    "lr": 0.0029664029600825195,
                    "end_lr_factor": 0.07533959100723438,
                    "n_epochs": 27,
                    "weight_decay": 7.695847710412437e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 26,
                    "lr": 0.007956658653858828,
                    "end_lr_factor": 0.10416076552399124,
                    "n_epochs": 40,
                    "weight_decay": 0.00022812591042582008,
                    "batch_size": 256
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 72,
                    "lr": 0.003284695547183904,
                    "end_lr_factor": 0.06266122800500469,
                    "n_epochs": 44,
                    "weight_decay": 3.639580828780465e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 476,
                    "lr": 0.05193153156677799,
                    "end_lr_factor": 0.027896214434760272,
                    "n_epochs": 25,
                    "weight_decay": 3.5814140318244396e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 4,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 267,
                    "lr": 0.0017811845325697473,
                    "end_lr_factor": 0.17943024534798788,
                    "n_epochs": 22,
                    "weight_decay": 1.9820856339440456e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}
{
    "1053": {
        "End2End_cpu": {
            "score_train": [
                -0.8332499861717224,
                -0.8272500038146973,
                -0.8184999823570251,
                -0.8209999799728394,
                -0.8182500004768372
            ],
            "score_test": [
                -0.8080000281333923,
                -0.8100000023841858,
                -0.8199999928474426,
                -0.800000011920929,
                -0.8240000009536743
            ],
            "t_fit": [
                25.996116921305656,
                8.463821742683649,
                7.826718546450138,
                15.487207852303982,
                12.7897422388196
            ],
            "t_inference": [
                0.8057630136609077,
                0.25507279112935066,
                0.3622424639761448,
                0.38892074301838875,
                0.48938602954149246
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 341,
                    "lr": 0.002333859604684194,
                    "end_lr_factor": 0.1999516438234677,
                    "n_epochs": 16,
                    "weight_decay": 2.0283919064776996e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 361,
                    "lr": 0.0016708144804642895,
                    "end_lr_factor": 0.7436199812214711,
                    "n_epochs": 10,
                    "weight_decay": 1.4105268453114942e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 210,
                    "lr": 0.006122716721786925,
                    "end_lr_factor": 0.20166046311513766,
                    "n_epochs": 10,
                    "weight_decay": 5.581833431306652e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 133,
                    "lr": 0.0064336476056813105,
                    "end_lr_factor": 0.331400861325567,
                    "n_epochs": 15,
                    "weight_decay": 2.0623407001492688e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 220,
                    "lr": 0.005944127798290718,
                    "end_lr_factor": 0.5375399648794708,
                    "n_epochs": 11,
                    "weight_decay": 2.2787072951260122e-05,
                    "batch_size": 384
                }
            ]
        }
    }
}
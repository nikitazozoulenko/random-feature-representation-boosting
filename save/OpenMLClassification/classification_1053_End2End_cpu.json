{
    "1053": {
        "End2End_cpu": {
            "score_train": [
                -0.8182500004768372,
                -0.8252500295639038,
                -0.8097500205039978,
                -0.8165000081062317,
                -0.8142499923706055
            ],
            "score_test": [
                -0.8059999942779541,
                -0.8059999942779541,
                -0.8209999799728394,
                -0.7929999828338623,
                -0.8230000138282776
            ],
            "t_fit": [
                12.54072429984808,
                63.68237276747823,
                7.675085134804249,
                2.9287853315472603,
                3.1871532201766968
            ],
            "t_inference": [
                0.2271142676472664,
                1.5427024997770786,
                0.15681658685207367,
                0.028134915977716446,
                0.055690620094537735
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 42,
                    "lr": 0.0544761188891818,
                    "end_lr_factor": 0.03059587537167688,
                    "n_epochs": 16,
                    "weight_decay": 0.00021859838067188073,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 408,
                    "lr": 0.0030192594536809975,
                    "end_lr_factor": 0.13401701200425134,
                    "n_epochs": 13,
                    "weight_decay": 0.0001286635568566186,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 69,
                    "lr": 0.03477087588865795,
                    "end_lr_factor": 0.07699061454360155,
                    "n_epochs": 13,
                    "weight_decay": 3.4076035759365937e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 19,
                    "lr": 0.09582128549086498,
                    "end_lr_factor": 0.11636613878930728,
                    "n_epochs": 15,
                    "weight_decay": 0.0006215464679232551,
                    "batch_size": 256
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 89,
                    "lr": 0.06359157650482442,
                    "end_lr_factor": 0.17331788636132678,
                    "n_epochs": 13,
                    "weight_decay": 2.1269456352695767e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}
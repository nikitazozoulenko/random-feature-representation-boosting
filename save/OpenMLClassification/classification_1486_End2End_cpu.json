{
    "1486": {
        "End2End_cpu": {
            "score_train": [
                -0.9860000014305115,
                -0.9825000166893005,
                -0.9779999852180481,
                -0.9827499985694885,
                -0.9950000047683716
            ],
            "score_test": [
                -0.9459999799728394,
                -0.9399999976158142,
                -0.9549999833106995,
                -0.9580000042915344,
                -0.9520000219345093
            ],
            "t_fit": [
                18.7445859760046,
                43.21164479106665,
                4.553011894226074,
                6.558362029492855,
                7.637761726975441
            ],
            "t_inference": [
                0.5409297347068787,
                0.9595578759908676,
                0.09943318367004395,
                0.13215231150388718,
                0.11213044822216034
            ],
            "hyperparams": [
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 320,
                    "lr": 0.002158822175195362,
                    "end_lr_factor": 0.04975578187730143,
                    "n_epochs": 14,
                    "weight_decay": 0.0005136452651197613,
                    "batch_size": 384
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 346,
                    "lr": 0.0069328410616004,
                    "end_lr_factor": 0.04152763990615663,
                    "n_epochs": 14,
                    "weight_decay": 5.420992322624361e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 306,
                    "lr": 0.004909139292091621,
                    "end_lr_factor": 0.06774171852222666,
                    "n_epochs": 16,
                    "weight_decay": 1.0376122495160666e-05,
                    "batch_size": 384
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 319,
                    "lr": 0.0034140266752493596,
                    "end_lr_factor": 0.19156962937168115,
                    "n_epochs": 19,
                    "weight_decay": 3.3803448462447844e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 345,
                    "lr": 0.00022809332660470879,
                    "end_lr_factor": 0.2247730166637844,
                    "n_epochs": 23,
                    "weight_decay": 4.199935057314981e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
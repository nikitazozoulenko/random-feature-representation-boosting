{
    "1486": {
        "End2End_cpu": {
            "score_train": [
                -0.9857500195503235,
                -0.9887499809265137,
                -0.9737499952316284,
                -0.9810000061988831,
                -0.996749997138977
            ],
            "score_test": [
                -0.9449999928474426,
                -0.9419999718666077,
                -0.9580000042915344,
                -0.9559999704360962,
                -0.953000009059906
            ],
            "t_fit": [
                24.46189933642745,
                39.44826517999172,
                33.6264409199357,
                6.449762975797057,
                17.10226154141128
            ],
            "t_inference": [
                0.8746646773070097,
                1.0021368861198425,
                1.1773317884653807,
                0.134449677541852,
                0.33023374527692795
            ],
            "hyperparams": [
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 360,
                    "lr": 0.0014757089691598269,
                    "end_lr_factor": 0.10235562439374729,
                    "n_epochs": 13,
                    "weight_decay": 2.5991689325376126e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 320,
                    "lr": 0.003514604556572905,
                    "end_lr_factor": 0.12147838847135559,
                    "n_epochs": 19,
                    "weight_decay": 8.503676026446128e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 458,
                    "lr": 0.0022435817808675986,
                    "end_lr_factor": 0.13070358655188888,
                    "n_epochs": 13,
                    "weight_decay": 1.4535517894309484e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 64,
                    "lr": 0.0007360698598228771,
                    "end_lr_factor": 0.31631791181958757,
                    "n_epochs": 11,
                    "weight_decay": 0.00014761908461378585,
                    "batch_size": 256
                },
                {
                    "in_dim": 174,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 361,
                    "lr": 0.0001916832360571864,
                    "end_lr_factor": 0.3596164423427032,
                    "n_epochs": 16,
                    "weight_decay": 1.1738805906367655e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}
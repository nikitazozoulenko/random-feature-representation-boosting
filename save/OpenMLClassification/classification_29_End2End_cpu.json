{
    "29": {
        "End2End_cpu": {
            "score_train": [
                -0.9637681245803833,
                -0.9601449370384216,
                -0.929347813129425,
                -0.9963768124580383,
                -0.9202898740768433
            ],
            "score_test": [
                -0.8115941882133484,
                -0.8478260636329651,
                -0.8695651888847351,
                -0.8188405632972717,
                -0.8840579986572266
            ],
            "t_fit": [
                18.461890529841185,
                3.808585498481989,
                4.750675402581692,
                7.809532295912504,
                8.255801662802696
            ],
            "t_inference": [
                0.1706758849322796,
                0.05228610336780548,
                0.05703131854534149,
                0.03909854590892792,
                0.08097793906927109
            ],
            "hyperparams": [
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 474,
                    "lr": 0.0023747274043665924,
                    "end_lr_factor": 0.33389730101856846,
                    "n_epochs": 19,
                    "weight_decay": 6.876729234951052e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 95,
                    "lr": 0.0014422419029608395,
                    "end_lr_factor": 0.5343861366322087,
                    "n_epochs": 12,
                    "weight_decay": 5.424664709134136e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 138,
                    "lr": 0.004602656766214828,
                    "end_lr_factor": 0.5879827817496845,
                    "n_epochs": 11,
                    "weight_decay": 3.329503949066846e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 186,
                    "lr": 0.00021857868985268185,
                    "end_lr_factor": 0.058699350106079656,
                    "n_epochs": 31,
                    "weight_decay": 0.00038657130819646753,
                    "batch_size": 384
                },
                {
                    "in_dim": 47,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 210,
                    "lr": 0.006546639392605592,
                    "end_lr_factor": 0.11303129725339633,
                    "n_epochs": 16,
                    "weight_decay": 5.3372561977421314e-05,
                    "batch_size": 256
                }
            ]
        }
    }
}
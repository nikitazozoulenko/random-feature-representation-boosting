{
    "4534": {
        "End2End_cpu": {
            "score_train": [
                -0.9929999709129333,
                -0.9929999709129333,
                -0.9917500019073486,
                -0.9932500123977661,
                -0.9927499890327454
            ],
            "score_test": [
                -0.9610000252723694,
                -0.9599999785423279,
                -0.9729999899864197,
                -0.9449999928474426,
                -0.9549999833106995
            ],
            "t_fit": [
                32.69411297887564,
                163.5182019919157,
                85.01825515925884,
                38.846512131392956,
                39.68213211745024
            ],
            "t_inference": [
                0.42409565299749374,
                1.589226208627224,
                1.1199860349297523,
                0.38745519518852234,
                0.33818551152944565
            ],
            "hyperparams": [
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 461,
                    "lr": 0.0007510418138777543,
                    "end_lr_factor": 0.7568292060167615,
                    "n_epochs": 42,
                    "weight_decay": 6.218704727769077e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 494,
                    "lr": 0.000254744894240345,
                    "end_lr_factor": 0.03209817870899145,
                    "n_epochs": 42,
                    "weight_decay": 0.0005592003594782627,
                    "batch_size": 256
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 343,
                    "lr": 0.0001824412301421009,
                    "end_lr_factor": 0.28350953395379697,
                    "n_epochs": 30,
                    "weight_decay": 0.0002493918134324452,
                    "batch_size": 256
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 233,
                    "lr": 0.0007113575210887429,
                    "end_lr_factor": 0.3854691259466882,
                    "n_epochs": 29,
                    "weight_decay": 3.4130223075339542e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 461,
                    "lr": 0.0007510418138777543,
                    "end_lr_factor": 0.7568292060167615,
                    "n_epochs": 42,
                    "weight_decay": 6.218704727769077e-05,
                    "batch_size": 512
                }
            ]
        }
    }
}
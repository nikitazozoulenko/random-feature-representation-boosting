{
    "4534": {
        "End2End_cpu": {
            "score_train": [
                -0.9940000176429749,
                -0.9929999709129333,
                -0.9919999837875366,
                -0.9937499761581421,
                -0.9927499890327454
            ],
            "score_test": [
                -0.9649999737739563,
                -0.9639999866485596,
                -0.9700000286102295,
                -0.9440000057220459,
                -0.9559999704360962
            ],
            "t_fit": [
                46.03839944303036,
                74.7711191251874,
                39.01697801798582,
                76.20808647572994,
                47.438247971236706
            ],
            "t_inference": [
                0.26316341012716293,
                0.42659977823495865,
                0.23321875929832458,
                0.43816397339105606,
                0.8262336477637291
            ],
            "hyperparams": [
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 411,
                    "lr": 0.0014522182166008448,
                    "end_lr_factor": 0.04786973010562664,
                    "n_epochs": 42,
                    "weight_decay": 0.0009940994492896192,
                    "batch_size": 128
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 165,
                    "lr": 0.0046919872263792555,
                    "end_lr_factor": 0.010235956676663278,
                    "n_epochs": 50,
                    "weight_decay": 0.0002223818077623948,
                    "batch_size": 128
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 139,
                    "lr": 0.0026298645580162807,
                    "end_lr_factor": 0.04545216116149548,
                    "n_epochs": 46,
                    "weight_decay": 2.9215866015012217e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 127,
                    "lr": 0.0034702669886504172,
                    "end_lr_factor": 0.010994335574766204,
                    "n_epochs": 48,
                    "weight_decay": 0.0003142880890840109,
                    "batch_size": 128
                },
                {
                    "in_dim": 68,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 329,
                    "lr": 0.00032486039808368267,
                    "end_lr_factor": 0.2034855945342239,
                    "n_epochs": 26,
                    "weight_decay": 5.608076768997658e-05,
                    "batch_size": 384
                }
            ]
        }
    }
}
{
    "23381": {
        "End2End_cpu": {
            "score_train": [
                -0.7049999833106995,
                -0.8174999952316284,
                -0.9474999904632568,
                -0.9975000023841858,
                -0.7350000143051147
            ],
            "score_test": [
                -0.5899999737739563,
                -0.6299999952316284,
                -0.5799999833106995,
                -0.49000000953674316,
                -0.5400000214576721
            ],
            "t_fit": [
                3.3406196385622025,
                2.6563910096883774,
                2.7493333630263805,
                3.1001013927161694,
                0.48335596919059753
            ],
            "t_inference": [
                0.17688274383544922,
                0.11554255336523056,
                0.054249584674835205,
                0.02234053611755371,
                0.024763241410255432
            ],
            "hyperparams": [
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 360,
                    "lr": 0.06201035997580235,
                    "end_lr_factor": 0.013684033259044387,
                    "n_epochs": 11,
                    "weight_decay": 4.54224403094307e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 443,
                    "lr": 0.009884750298845798,
                    "end_lr_factor": 0.05657360579359704,
                    "n_epochs": 14,
                    "weight_decay": 1.0217092848414137e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 115,
                    "lr": 0.0726168760945771,
                    "end_lr_factor": 0.5163205436618927,
                    "n_epochs": 13,
                    "weight_decay": 2.5359589179287728e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 119,
                    "lr": 0.06181845191598088,
                    "end_lr_factor": 0.02722849701310605,
                    "n_epochs": 36,
                    "weight_decay": 0.00027449838008415694,
                    "batch_size": 128
                },
                {
                    "in_dim": 156,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 411,
                    "lr": 8.72980347030571e-05,
                    "end_lr_factor": 0.13191939185690493,
                    "n_epochs": 10,
                    "weight_decay": 1.3748597743232042e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
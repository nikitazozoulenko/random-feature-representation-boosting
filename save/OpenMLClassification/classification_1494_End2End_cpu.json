{
    "1494": {
        "End2End_cpu": {
            "score_train": [
                -0.9561611413955688,
                -0.9798578023910522,
                -0.9241706132888794,
                -0.9952606558799744,
                -0.9514217972755432
            ],
            "score_test": [
                -0.8625592589378357,
                -0.8767772316932678,
                -0.8625592589378357,
                -0.8909952640533447,
                -0.8578199148178101
            ],
            "t_fit": [
                12.535909667611122,
                26.922117218375206,
                7.613499209284782,
                9.172258049249649,
                3.1180103421211243
            ],
            "t_inference": [
                0.06893257796764374,
                0.2503657191991806,
                0.08675907552242279,
                0.07865744829177856,
                0.06322325766086578
            ],
            "hyperparams": [
                {
                    "in_dim": 41,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 283,
                    "lr": 0.00459124578838066,
                    "end_lr_factor": 0.2901633449784574,
                    "n_epochs": 12,
                    "weight_decay": 2.529522383386369e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 41,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 322,
                    "lr": 0.006829628352889455,
                    "end_lr_factor": 0.28740560316472685,
                    "n_epochs": 27,
                    "weight_decay": 2.0337590603296407e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 41,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 74,
                    "lr": 0.004684325419697727,
                    "end_lr_factor": 0.09707906655803776,
                    "n_epochs": 14,
                    "weight_decay": 1.8042936503378008e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 41,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 455,
                    "lr": 0.00012141813968952454,
                    "end_lr_factor": 0.15114790418674484,
                    "n_epochs": 43,
                    "weight_decay": 0.0006073719810962049,
                    "batch_size": 256
                },
                {
                    "in_dim": 41,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 244,
                    "lr": 0.005393925000372151,
                    "end_lr_factor": 0.27443502397946085,
                    "n_epochs": 16,
                    "weight_decay": 8.179976698795679e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
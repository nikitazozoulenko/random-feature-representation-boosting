{
    "40983": {
        "End2End_cpu": {
            "score_train": [
                -0.990183413028717,
                -0.9922500848770142,
                -0.9888917803764343,
                -0.9909583926200867,
                -0.9914772510528564
            ],
            "score_test": [
                -0.9927685856819153,
                -0.9876033067703247,
                -0.9814049601554871,
                -0.9886363744735718,
                -0.9896587133407593
            ],
            "t_fit": [
                116.38722006976604,
                115.63531506061554,
                44.962596356868744,
                19.261301293969154,
                25.264884397387505
            ],
            "t_inference": [
                0.8052657321095467,
                0.9654022976756096,
                0.48697560280561447,
                0.49252787232398987,
                0.5249908566474915
            ],
            "hyperparams": [
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 240,
                    "lr": 0.04468402766831739,
                    "end_lr_factor": 0.013130661446326623,
                    "n_epochs": 46,
                    "weight_decay": 0.0003089238262044609,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 405,
                    "lr": 0.036854428059542525,
                    "end_lr_factor": 0.01923535983912303,
                    "n_epochs": 36,
                    "weight_decay": 0.0003974600067834841,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 212,
                    "lr": 0.06709493404725643,
                    "end_lr_factor": 0.4131731287812942,
                    "n_epochs": 26,
                    "weight_decay": 1.4733364343604142e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 431,
                    "lr": 0.004570563099801453,
                    "end_lr_factor": 0.15751320499779725,
                    "n_epochs": 12,
                    "weight_decay": 2.9375384576328313e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 264,
                    "lr": 0.06631971642481921,
                    "end_lr_factor": 0.0799583183037696,
                    "n_epochs": 21,
                    "weight_decay": 1.9384293368378948e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}
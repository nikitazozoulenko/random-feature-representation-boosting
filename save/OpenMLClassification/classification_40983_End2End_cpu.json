{
    "40983": {
        "End2End_cpu": {
            "score_train": [
                -0.9899250864982605,
                -0.9927667379379272,
                -0.9930250644683838,
                -0.9907000660896301,
                -0.9901859760284424
            ],
            "score_test": [
                -0.9917355179786682,
                -0.9845041036605835,
                -0.98037189245224,
                -0.9845041036605835,
                -0.9927611351013184
            ],
            "t_fit": [
                142.9880995452404,
                4.573243960738182,
                177.7826090157032,
                6.69936965405941,
                14.39154364168644
            ],
            "t_inference": [
                0.20342200994491577,
                0.08308060467243195,
                1.2183042168617249,
                0.18871748447418213,
                0.37636588513851166
            ],
            "hyperparams": [
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 110,
                    "lr": 0.003990584187116172,
                    "end_lr_factor": 0.26260924821004644,
                    "n_epochs": 22,
                    "weight_decay": 2.2709007373185594e-05,
                    "batch_size": 128
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 229,
                    "lr": 0.0066023511246596535,
                    "end_lr_factor": 0.10673322321605684,
                    "n_epochs": 16,
                    "weight_decay": 6.951596360214634e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 497,
                    "lr": 0.0019068513126720159,
                    "end_lr_factor": 0.49415184637700293,
                    "n_epochs": 49,
                    "weight_decay": 1.789472587425254e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 295,
                    "lr": 0.0073412772524091,
                    "end_lr_factor": 0.3023139923983223,
                    "n_epochs": 14,
                    "weight_decay": 1.7548154403017538e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 5,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 173,
                    "lr": 0.009295719799601566,
                    "end_lr_factor": 0.3049560486205839,
                    "n_epochs": 11,
                    "weight_decay": 2.549698356293507e-06,
                    "batch_size": 128
                }
            ]
        }
    }
}
{
    "1461": {
        "End2End_cpu": {
            "score_train": [
                -0.9647499918937683,
                -0.9384999871253967,
                -0.9492499828338623,
                -0.9207500219345093,
                -0.9355000257492065
            ],
            "score_test": [
                -0.8899999856948853,
                -0.8980000019073486,
                -0.8980000019073486,
                -0.9020000100135803,
                -0.9100000262260437
            ],
            "t_fit": [
                35.879187136888504,
                5.696112833917141,
                42.65397319942713,
                10.737817354500294,
                4.223319612443447
            ],
            "t_inference": [
                0.46637992560863495,
                0.1356521174311638,
                0.7771906182169914,
                0.4729849323630333,
                0.16744757443666458
            ],
            "hyperparams": [
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 194,
                    "lr": 0.07041830285016017,
                    "end_lr_factor": 0.8133545002715508,
                    "n_epochs": 28,
                    "weight_decay": 5.316480195825888e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 354,
                    "lr": 0.06642640700916837,
                    "end_lr_factor": 0.3472767449798701,
                    "n_epochs": 15,
                    "weight_decay": 2.7561646702258206e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 330,
                    "lr": 0.0590390219972749,
                    "end_lr_factor": 0.10960392366069656,
                    "n_epochs": 23,
                    "weight_decay": 1.4617103440225666e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 197,
                    "lr": 0.026025957327376104,
                    "end_lr_factor": 0.04102352956608573,
                    "n_epochs": 10,
                    "weight_decay": 1.3290513058357458e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 135,
                    "lr": 0.023381399169813633,
                    "end_lr_factor": 0.06358608056800875,
                    "n_epochs": 10,
                    "weight_decay": 2.5976863361920284e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}
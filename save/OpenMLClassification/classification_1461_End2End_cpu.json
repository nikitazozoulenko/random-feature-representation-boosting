{
    "1461": {
        "End2End_cpu": {
            "score_train": [
                -0.9474999904632568,
                -0.9825000166893005,
                -0.9294999837875366,
                -0.9304999709129333,
                -0.9514999985694885
            ],
            "score_test": [
                -0.8989999890327454,
                -0.8830000162124634,
                -0.9079999923706055,
                -0.8989999890327454,
                -0.9020000100135803
            ],
            "t_fit": [
                10.27804608643055,
                48.84972910769284,
                53.862155582755804,
                52.388074081391096,
                52.935860412195325
            ],
            "t_inference": [
                0.49267934635281563,
                1.446903433650732,
                2.417127275839448,
                2.187047004699707,
                1.6657765451818705
            ],
            "hyperparams": [
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 283,
                    "lr": 0.008326547304422555,
                    "end_lr_factor": 0.48893014110504235,
                    "n_epochs": 10,
                    "weight_decay": 2.345484279099907e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 405,
                    "lr": 0.0052037611430242065,
                    "end_lr_factor": 0.27004938412448803,
                    "n_epochs": 11,
                    "weight_decay": 5.130252151145509e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 452,
                    "lr": 0.005498295711417591,
                    "end_lr_factor": 0.09959556345409788,
                    "n_epochs": 11,
                    "weight_decay": 3.233995860328718e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 503,
                    "lr": 0.003430229289669129,
                    "end_lr_factor": 0.1570079646475811,
                    "n_epochs": 12,
                    "weight_decay": 5.185361801585662e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 51,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 392,
                    "lr": 0.003502493657218906,
                    "end_lr_factor": 0.09541742876500908,
                    "n_epochs": 12,
                    "weight_decay": 1.4989533720686724e-06,
                    "batch_size": 384
                }
            ]
        }
    }
}
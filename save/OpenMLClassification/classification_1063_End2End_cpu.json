{
    "1063": {
        "End2End_cpu": {
            "score_train": [
                -0.853717029094696,
                -0.8633093237876892,
                -0.9665071964263916,
                -0.8564593195915222,
                -0.8660287261009216
            ],
            "score_test": [
                -0.8761904835700989,
                -0.8285714387893677,
                -0.817307710647583,
                -0.8461538553237915,
                -0.8365384340286255
            ],
            "t_fit": [
                2.221162624657154,
                2.2346819937229156,
                2.8425824865698814,
                2.254546046257019,
                0.7455054894089699
            ],
            "t_inference": [
                0.06095132976770401,
                0.07750256359577179,
                0.024487584829330444,
                0.05556818097829819,
                0.02777986228466034
            ],
            "hyperparams": [
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 431,
                    "lr": 0.004570563099801453,
                    "end_lr_factor": 0.15751320499779725,
                    "n_epochs": 12,
                    "weight_decay": 2.9375384576328313e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 281,
                    "lr": 0.007139190865945739,
                    "end_lr_factor": 0.9908984634711898,
                    "n_epochs": 10,
                    "weight_decay": 1.9421716952966e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 309,
                    "lr": 0.00014303189597823015,
                    "end_lr_factor": 0.13050796439741733,
                    "n_epochs": 35,
                    "weight_decay": 0.0007340968508350945,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 308,
                    "lr": 0.01257619026057406,
                    "end_lr_factor": 0.1752803755056348,
                    "n_epochs": 13,
                    "weight_decay": 1.556909541828461e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 21,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 3,
                    "hidden_dim": 231,
                    "lr": 0.010088592100720247,
                    "end_lr_factor": 0.049575472370886414,
                    "n_epochs": 14,
                    "weight_decay": 1.0478567527085746e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
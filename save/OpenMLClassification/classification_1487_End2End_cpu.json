{
    "1487": {
        "End2End_cpu": {
            "score_train": [
                -0.9437592625617981,
                -0.9615194797515869,
                -0.9590528011322021,
                -0.9620128273963928,
                -0.9516765475273132
            ],
            "score_test": [
                -0.9191321730613708,
                -0.9408283829689026,
                -0.9230769276618958,
                -0.9526627063751221,
                -0.9604743123054504
            ],
            "t_fit": [
                10.027694404125214,
                6.286096949130297,
                2.688499540090561,
                7.131866775453091,
                1.2088858969509602
            ],
            "t_inference": [
                0.28861358389258385,
                0.22005949541926384,
                0.08912414684891701,
                0.30611224099993706,
                0.059292640537023544
            ],
            "hyperparams": [
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 359,
                    "lr": 0.005477337818357601,
                    "end_lr_factor": 0.13448110720523812,
                    "n_epochs": 12,
                    "weight_decay": 2.8788592770368307e-06,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 6,
                    "hidden_dim": 227,
                    "lr": 0.009979113182512793,
                    "end_lr_factor": 0.3362112985560992,
                    "n_epochs": 12,
                    "weight_decay": 1.3233017808366274e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 472,
                    "lr": 0.0031512178863934075,
                    "end_lr_factor": 0.1868245187293964,
                    "n_epochs": 11,
                    "weight_decay": 1.6722955492215327e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 8,
                    "hidden_dim": 261,
                    "lr": 0.002983059015317966,
                    "end_lr_factor": 0.16797400777679053,
                    "n_epochs": 10,
                    "weight_decay": 1.3032943403961076e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 412,
                    "lr": 0.0022406930338660126,
                    "end_lr_factor": 0.2954956111811025,
                    "n_epochs": 10,
                    "weight_decay": 2.710225512095216e-06,
                    "batch_size": 512
                }
            ]
        }
    }
}
{
    "1487": {
        "End2End_cpu": {
            "score_train": [
                -0.9605327844619751,
                -0.9679328799247742,
                -0.9580661058425903,
                -0.9516527056694031,
                -0.949211061000824
            ],
            "score_test": [
                -0.942800760269165,
                -0.9368836283683777,
                -0.9309664964675903,
                -0.9546350836753845,
                -0.9545454382896423
            ],
            "t_fit": [
                15.849088035523891,
                6.14314503967762,
                11.951007775962353,
                21.04428891092539,
                10.551042899489403
            ],
            "t_inference": [
                0.47979553043842316,
                0.11351831257343292,
                0.3687336891889572,
                0.6351333111524582,
                0.38121289759874344
            ],
            "hyperparams": [
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 263,
                    "lr": 0.022414391417549112,
                    "end_lr_factor": 0.07931587069836687,
                    "n_epochs": 11,
                    "weight_decay": 0.00014313541133550902,
                    "batch_size": 128
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 350,
                    "lr": 0.02260431790373708,
                    "end_lr_factor": 0.15718858748263706,
                    "n_epochs": 19,
                    "weight_decay": 4.85333949586916e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 340,
                    "lr": 0.016244261831161105,
                    "end_lr_factor": 0.033739662416512904,
                    "n_epochs": 13,
                    "weight_decay": 0.00016893806027344123,
                    "batch_size": 256
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 438,
                    "lr": 0.0108572175307655,
                    "end_lr_factor": 0.354029497510362,
                    "n_epochs": 18,
                    "weight_decay": 1.9571340937055974e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 72,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 10,
                    "hidden_dim": 192,
                    "lr": 0.031319339162134065,
                    "end_lr_factor": 0.2554261214579338,
                    "n_epochs": 11,
                    "weight_decay": 6.76435392207543e-06,
                    "batch_size": 256
                }
            ]
        }
    }
}
{
    "44": {
        "End2End_cpu": {
            "score_train": [
                -0.991032600402832,
                -0.9926650524139404,
                -0.9842433929443359,
                -0.9847867488861084,
                -0.9883183836936951
            ],
            "score_test": [
                -0.9554831981658936,
                -0.928260862827301,
                -0.9413043260574341,
                -0.935869574546814,
                -0.9434782862663269
            ],
            "t_fit": [
                16.139602318406105,
                11.44620943069458,
                14.600668787956238,
                3.345863088965416,
                11.832764968276024
            ],
            "t_inference": [
                0.3372596204280853,
                0.12449780106544495,
                0.29551200568675995,
                0.11118733882904053,
                0.26056377589702606
            ],
            "hyperparams": [
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 294,
                    "lr": 0.006510201835296209,
                    "end_lr_factor": 0.12794905591084868,
                    "n_epochs": 14,
                    "weight_decay": 4.38768126280707e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 411,
                    "lr": 0.006347820443091665,
                    "end_lr_factor": 0.9217695948028819,
                    "n_epochs": 33,
                    "weight_decay": 9.77063958433665e-05,
                    "batch_size": 512
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 5,
                    "hidden_dim": 204,
                    "lr": 0.03686588081873083,
                    "end_lr_factor": 0.1591198873840429,
                    "n_epochs": 17,
                    "weight_decay": 2.167124356388998e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 378,
                    "lr": 0.0016996068670646208,
                    "end_lr_factor": 0.0673019911403325,
                    "n_epochs": 10,
                    "weight_decay": 0.0002843388151812021,
                    "batch_size": 512
                },
                {
                    "in_dim": 57,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 7,
                    "hidden_dim": 128,
                    "lr": 0.02253795608839162,
                    "end_lr_factor": 0.08510944270185075,
                    "n_epochs": 11,
                    "weight_decay": 4.078879476016282e-05,
                    "batch_size": 128
                }
            ]
        }
    }
}
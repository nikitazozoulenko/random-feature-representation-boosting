{
    "1049": {
        "End2End_cpu": {
            "score_train": [
                -0.9991423487663269,
                -0.9442538619041443,
                -0.9845626354217529,
                -0.9297343492507935,
                -0.9948586225509644
            ],
            "score_test": [
                -0.8869863152503967,
                -0.9246575236320496,
                -0.8972602486610413,
                -0.9175257682800293,
                -0.907216489315033
            ],
            "t_fit": [
                22.53867793083191,
                6.233871437609196,
                6.3979248851537704,
                0.5356502458453178,
                5.967624858021736
            ],
            "t_inference": [
                0.13616470247507095,
                0.1642625778913498,
                0.09984904527664185,
                0.01495814323425293,
                0.033373601734638214
            ],
            "hyperparams": [
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 9,
                    "hidden_dim": 127,
                    "lr": 0.0034702669886504172,
                    "end_lr_factor": 0.010994335574766204,
                    "n_epochs": 48,
                    "weight_decay": 0.0003142880890840109,
                    "batch_size": 128
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 431,
                    "lr": 0.004570563099801453,
                    "end_lr_factor": 0.15751320499779725,
                    "n_epochs": 12,
                    "weight_decay": 2.9375384576328313e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 250,
                    "lr": 0.014185071575191298,
                    "end_lr_factor": 0.16827438307608153,
                    "n_epochs": 26,
                    "weight_decay": 1.183808101308875e-05,
                    "batch_size": 256
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 110,
                    "lr": 0.004563595281728556,
                    "end_lr_factor": 0.07405791156751228,
                    "n_epochs": 10,
                    "weight_decay": 6.251387524850651e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 314,
                    "lr": 0.008663300161605533,
                    "end_lr_factor": 0.018251602206779884,
                    "n_epochs": 48,
                    "weight_decay": 0.00024162700456786546,
                    "batch_size": 128
                }
            ]
        }
    }
}
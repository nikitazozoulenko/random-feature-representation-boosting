{
    "1049": {
        "End2End_cpu": {
            "score_train": [
                -0.9476844072341919,
                -0.9554030895233154,
                -0.9511149525642395,
                -0.9880034327507019,
                -0.9940016865730286
            ],
            "score_test": [
                -0.9075342416763306,
                -0.9212328791618347,
                -0.8972602486610413,
                -0.9037800431251526,
                -0.9175257682800293
            ],
            "t_fit": [
                5.411138281226158,
                7.206289976835251,
                3.1077187061309814,
                4.042993754148483,
                2.084643319249153
            ],
            "t_inference": [
                0.03923314809799194,
                0.04869408905506134,
                0.1114698052406311,
                0.03912337124347687,
                0.012189269065856934
            ],
            "hyperparams": [
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 417,
                    "lr": 0.0010430625398821004,
                    "end_lr_factor": 0.19025943992815142,
                    "n_epochs": 11,
                    "weight_decay": 2.10032016131688e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 271,
                    "lr": 0.009760890172387803,
                    "end_lr_factor": 0.18739075939006508,
                    "n_epochs": 27,
                    "weight_decay": 5.0942337029949706e-06,
                    "batch_size": 256
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 4,
                    "hidden_dim": 241,
                    "lr": 0.0062207257034236196,
                    "end_lr_factor": 0.28270079157494127,
                    "n_epochs": 10,
                    "weight_decay": 1.6959567953526126e-06,
                    "batch_size": 128
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 2,
                    "hidden_dim": 288,
                    "lr": 0.004776215247687721,
                    "end_lr_factor": 0.6547478144631458,
                    "n_epochs": 36,
                    "weight_decay": 2.9187972883646018e-06,
                    "batch_size": 384
                },
                {
                    "in_dim": 37,
                    "out_dim": 1,
                    "loss": "bce",
                    "bottleneck_dim": 512,
                    "n_blocks": 1,
                    "hidden_dim": 108,
                    "lr": 0.007490953708375965,
                    "end_lr_factor": 0.37432629313530025,
                    "n_epochs": 37,
                    "weight_decay": 0.00017098587018680815,
                    "batch_size": 128
                }
            ]
        }
    }
}